{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8401399,"sourceType":"datasetVersion","datasetId":4998845},{"sourceId":8404739,"sourceType":"datasetVersion","datasetId":5001243}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"color_names = [\n    \"Red\",\n    \"Orange\",\n    \"Yellow\",\n    \"Green\",\n    \"Blue\",\n    \"Purple\",\n    \"Pink\",\n    \"Brown\",\n    \"Black\",\n    \"White\",\n    \"Gray\",\n    \"Grey\",\n    \"Turquoise\",\n    \"Beige\",\n    \"Magenta\",\n    \"Cyan\",\n    \"Lavender\",\n    \"Indigo\",\n    \"Teal\",\n    \"Maroon\",\n    \"Olive\",\n    \"Violet\",\n    \"Gold\",\n    \"Silver\",\n    \"Bronze\",\n    \"Cream\",\n    \"Charcoal\",\n    \"Mint\",\n    \"Peach\",\n    \"Tan\",\n    \"Lemon\"\n]\n\ncolor_combinations = [\n    \"Indigo Blue\",\n    \"Navy Blue\",\n    \"Sky Blue\",\n    \"Teal Green\",\n    \"Mint Green\",\n    \"Olive Green\",\n    \"Burgundy Red\",\n    \"Crimson Red\",\n    \"Coral Pink\",\n    \"Peach Pink\",\n    \"Lavender Purple\",\n    \"Plum Purple\",\n    \"Mustard Yellow\",\n    \"Lemon Yellow\",\n    \"Slate Gray\",\n    \"Charcoal Gray\",\n    \"Maroon Red\",\n    \"Turquoise Blue\",\n    \"Eggplant Purple\",\n    \"Tangerine Orange\",\n    \"Forest Green\",\n    \"Ruby Red\",\n    \"Sand Beige\",\n    \"Salmon Pink\",\n    \"Cobalt Blue\",\n    \"Periwinkle Blue\",\n    \"Mauve Purple\",\n    \"Cyan Blue\",\n    \"Mahogany Brown\",\n    \"Gold Yellow\"\n]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_variations= set()\ncombination_variations =set()\nfor color in color_names:\n    color_variations.add(color.upper()) \nfor color in color_combinations:\n    combination_variations.add(color.upper()) \n\ncolor_names = list(color_variations)\ncolor_combinations = list(combination_variations)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_combinations","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\ndef replace_colors(description):\n    description = description.upper()\n    \n    for combination in color_combinations:\n        if combination.upper() in description:\n            replacement_combination = random.choice(color_combinations)\n            while replacement_combination.upper() == combination.upper():\n                replacement_combination = random.choice(color_combinations)\n            description = description.replace(combination.upper(), replacement_combination.upper(), 1)\n            return description\n    \n    for color in color_names:\n        if color.upper() in description:\n            replacement_color = random.choice(color_names)\n            while replacement_color.upper() == color.upper():\n                replacement_color = random.choice(color_names)\n            description = description.replace(color.upper(), replacement_color.upper(), 1)\n            return description\n    \n    return description\n\ndescription = \"full pose of BOMBERS for Men. Long sleeve reversible bomber jacket in black. Ombré paneling at interior in tones of pink, blue, mauve and green. Ribbed trim throughout. Concealed zip closure with snap-down flap at hem. Snap-down angled flap pockets at front. Zippered cargo pocket with pen slots at left sleeve. Angled welt pockets with concealed zip closures at reverse. Tonal and contrast stitching in black.\"\nprint(replace_colors(description))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename =\"/kaggle/input/frgtyuji/generated_instruction-1 (4).csv\"\nimport csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"description_dict={}\nwith open(filename, 'r', encoding='utf-8') as csvfile:\n    reader = csv.DictReader(csvfile)\n    for row in reader:\n        index = row[\"image_index\"]\n        description = row[\"Description\"].replace('\\n', '')\n        if index in description_dict:\n            if description not in description_dict[index]:\n                description_dict[index].append(description)\n        else:\n            description_dict[index] = [description]\ndescription_list = list(description_dict.values())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"description_list[1000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport string\n\ndescription_dict_modified = {}\nfor index, descriptions in description_dict.items():\n    modified_descriptions = []\n    for description in descriptions:\n        modified_description = replace_colors(description)\n        modified_descriptions.append(modified_description)\n    description_dict_modified[index] = modified_descriptions\n    \nwith open('output_description_list.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['image_index', 'Description', 'Modified Description']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n    writer.writeheader()\n    for index, descriptions in description_dict.items():\n        modified_descriptions = description_dict_modified[index]\n        for description, modified_description in zip(descriptions, modified_descriptions):\n            writer.writerow({'image_index': index, 'Description': description, 'Modified Description': modified_description})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install diffusers","metadata":{"execution":{"iopub.status.busy":"2024-05-14T08:18:16.981618Z","iopub.execute_input":"2024-05-14T08:18:16.981957Z","iopub.status.idle":"2024-05-14T08:18:33.275721Z","shell.execute_reply.started":"2024-05-14T08:18:16.981931Z","shell.execute_reply":"2024-05-14T08:18:33.274722Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting diffusers\n  Downloading diffusers-0.27.2-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (6.11.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers) (3.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.2 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.22.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers) (2.31.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.4.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (9.5.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.9.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (2024.2.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.2->diffusers) (3.1.1)\nDownloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: diffusers\nSuccessfully installed diffusers-0.27.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom diffusers import StableDiffusionXLPipeline, UNet2DConditionModel, EulerDiscreteScheduler\nfrom huggingface_hub import hf_hub_download\nfrom safetensors.torch import load_file\n\nbase = \"stabilityai/stable-diffusion-xl-base-1.0\"\nrepo = \"ByteDance/SDXL-Lightning\"\nckpt = \"sdxl_lightning_4step_unet.safetensors\" \n\nunet = UNet2DConditionModel.from_config(base, subfolder=\"unet\")\nunet.load_state_dict(load_file(hf_hub_download(repo, ckpt)))\npipe = StableDiffusionXLPipeline.from_pretrained(base, unet=unet, torch_dtype=torch.float32, variant=\"fp16\")\npipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T08:18:33.277833Z","iopub.execute_input":"2024-05-14T08:18:33.278148Z","iopub.status.idle":"2024-05-14T08:19:58.382922Z","shell.execute_reply.started":"2024-05-14T08:18:33.278113Z","shell.execute_reply":"2024-05-14T08:19:58.381758Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c6039d1a7f4eec8c8c49a291183602"}},"metadata":{}},{"name":"stderr","text":"2024-05-14 08:18:41.921091: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-14 08:18:41.921235: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-14 08:18:42.077522: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:244: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'diffusers.models.unets.unet_2d_condition.UNet2DConditionModel'>.load_config(...) followed by <class 'diffusers.models.unets.unet_2d_condition.UNet2DConditionModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"unet/config.json:   0%|          | 0.00/1.68k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"def486a222684a07b1d80f6c4b876b9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sdxl_lightning_4step_unet.safetensors:   0%|          | 0.00/5.14G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e7e1e854886425f853d1f26c865b0b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/609 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ca685d541494798bdfa68aaf6afdba1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96ae30d6c0614af5b1a16a44f325db26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/tokenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ff122c324844f838141a38ff8e0f39e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c62811c92544f49255630722d096af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4784ffdc5ff5483cb7940a349c43c180"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder_2/config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1735120d2c434220bdb186d0caf09e48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler/scheduler_config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be876b68481487fa926d0b8faf94923"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03b8957927014bea8614ce5b37daa2d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder_2/model.fp16.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beec9c8c439842b59edb2f5f929f2db0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70691664b7424d80b95b14c85b3a17fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b7097e82e364e73bef3c5e6d38fd5cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_2/special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebaf46558a03453c8fdcc33c59eb51cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_2/tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d64a28ae6ca4a29abcfac7348c689e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_2/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1ccfcdca309417490dc09a481ea1b0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7dd197ad48847a6a4b0a777054f5f2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_2/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9dd41f9f1b44b1ea580a0a5ae718e70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4316e25e199445a8ed9e916941a2424"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3a7ea6dda0f4fb6b1e94a42232408ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0f2c8ef5944439d9f365bd3e49ad7ad"}},"metadata":{}}]},{"cell_type":"code","source":"negative_prompt = \"(deformed iris, deformed pupils, semi_realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4, abnormal pose, non-standard pose, unnatural pose), (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting, amputation, cropped body, cut-off body, incomplete body, half body, partial body, torso only, cropped image, cut-off image, incomplete image, half image, partial image, missing body parts, multiple people, more than one person, group of people, crowd, ambiguous figures, unclear subjects\"","metadata":{"execution":{"iopub.status.busy":"2024-05-14T08:19:58.389861Z","iopub.execute_input":"2024-05-14T08:19:58.390219Z","iopub.status.idle":"2024-05-14T08:19:58.396228Z","shell.execute_reply.started":"2024-05-14T08:19:58.390185Z","shell.execute_reply":"2024-05-14T08:19:58.395231Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import csv","metadata":{"execution":{"iopub.status.busy":"2024-05-14T08:19:58.397566Z","iopub.execute_input":"2024-05-14T08:19:58.398003Z","iopub.status.idle":"2024-05-14T08:19:59.831962Z","shell.execute_reply.started":"2024-05-14T08:19:58.397953Z","shell.execute_reply":"2024-05-14T08:19:59.830899Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-05-14T08:20:11.016004Z","iopub.execute_input":"2024-05-14T08:20:11.016374Z","iopub.status.idle":"2024-05-14T08:20:11.020872Z","shell.execute_reply.started":"2024-05-14T08:20:11.016347Z","shell.execute_reply":"2024-05-14T08:20:11.019878Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T08:24:27.693588Z","iopub.execute_input":"2024-05-14T08:24:27.693979Z","iopub.status.idle":"2024-05-14T08:24:27.776734Z","shell.execute_reply.started":"2024-05-14T08:24:27.693948Z","shell.execute_reply":"2024-05-14T08:24:27.775590Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-05-14T08:24:33.687445Z","iopub.execute_input":"2024-05-14T08:24:33.688294Z","iopub.status.idle":"2024-05-14T08:24:33.694968Z","shell.execute_reply.started":"2024-05-14T08:24:33.688260Z","shell.execute_reply":"2024-05-14T08:24:33.693922Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"filename = \"/kaggle/input/gfvjhb/output_description_list.csv\"\nwith open(filename, 'r', encoding='utf-8') as csvfile:\n    reader = csv.DictReader(csvfile)\n    count = 0\n    prompts=[]\n    for row in reader:\n        if count >= 40:\n            break\n        description = row[\"Description\"]\n        new_description = row[\"Modified Description\"]\n        original_image = pipe([description, \"a full body for the image generation\", \"one person\", \"a normale front pose\", \"a based black backgound\", \"a realistic person\"], negative_prompt=negative_prompt, num_inference_steps=4, seed=0, guidance_scale=0).images[0].to(device)\n        print(description)\n        original_shape = original_image.size\n        original_style = extract_style_features(original_image)\n        original_image.save(f\"original_{count}.png\")\n        modified_image = pipe([new_description, \"a full body for the image generation\", \"one person\", \"a normale front pose\", \"a based black backgound\", \"a realistic person\"], negative_prompt=negative_prompt, num_inference_steps=4, seed=0, guidance_scale=0, target_shape=original_shape, target_style=original_style).images[0].to(device)\n        print(new_description)\n        modified_image.save(f\"modified_{count}.png\")\n        count += 1","metadata":{"execution":{"iopub.status.busy":"2024-05-14T08:25:33.060158Z","iopub.execute_input":"2024-05-14T08:25:33.060561Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffd529f10e1446e8b4812896281aa18f"}},"metadata":{}}]},{"cell_type":"code","source":"pipe(prompts, negative_prompt= negative_prompt, num_inference_steps=4, seed=0, guidance_scale=0 ).images[0]","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe([\"FRONT POSE OF HOODIES & ZIPUPS FOR WOMEN. LONG SLEEVE SWEATSHIRT IN HEATHER CYAN. BAND COLLAR. ZIP CLOSURE AND VERTICAL ZIPPERED WELT POCKETS AT FRONT. PEPLUM DETAIL AT WAIST. FLEECY INTERIOR. FULLY LINED. TONAL STITCHING. ZIPPERED SLEEVE CUFFS.\", \"A full body for the image generated\"], negative_prompt= negative_prompt, num_inference_steps=4, seed=0, guidance_scale=0).images[0]","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}